{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOs\n",
    "\n",
    "1) Iterate through the yes and no folder.<br>\n",
    "2) Extract keypoints of of each image and store them in a numpy array\n",
    "   of each class folder respectively. <br>\n",
    "3) Now append classes column for each class dataset.<br>\n",
    "4) Now concatenate both the datasets and shuffle the rows.\n",
    "<br><br>**Note :** Below functions take large amount of time in creating the dataset. (~25mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    frame = cv2.imread(img)\n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    aspect_ratio = frameWidth/frameHeight\n",
    "\n",
    "    inHeight = 368\n",
    "    inWidth = int(((aspect_ratio*inHeight)*8)//8)\n",
    "    \n",
    "    return inHeight, inWidth, frameWidth, frameHeight, frame\n",
    "\n",
    "\n",
    "def dataset(path):\n",
    "    protoFile = \"hand/pose_deploy.prototxt\"\n",
    "    weightsFile = \"hand/pose_iter_102000.caffemodel\"\n",
    "    imagePaths = list(paths.list_images(path))\n",
    "    threshold = 0\n",
    "    points = []\n",
    "    labels = []\n",
    "    nPoints = 22\n",
    "    net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "    # loop over the image paths\n",
    "    for imagePath in imagePaths:\n",
    "        # extract the class label from the filename\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        # load the input image (224x224) and preprocess it\n",
    "        img_h, img_w, frameWidth, frameHeight, img = preprocess(imagePath)\n",
    "        inpBlob = cv2.dnn.blobFromImage(img, 1.0 / 255, (img_w, img_h), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "        net.setInput(inpBlob)\n",
    "\n",
    "        output = net.forward()  \n",
    "\n",
    "        for i in range(nPoints):\n",
    "            # confidence map of corresponding body's part.\n",
    "            probMap = output[0, i, :, :]\n",
    "            probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "            # Find global maxima of the probMap. to determine location of Keypoint\n",
    "            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "            if prob > threshold :\n",
    "                # Add the point to the list if the probability is greater than the threshold\n",
    "                points.append((int(point[0]), int(point[1])))\n",
    "                if label == 'yes':\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "            else :\n",
    "                points.append(None) \n",
    "\n",
    "    points = np.array(points)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return points, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset csv file exists or not. \n",
    "if os.path.isfile('KPts_dataset.csv') is False:\n",
    "    path = 'D:\\Project_Ideas\\TeachableMachine_Local\\handPose\\dataset'\n",
    "    dataset(path)\n",
    "    \n",
    "    points, labels = dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classes = labels.copy()\n",
    "classes = pd.DataFrame(classes, columns=['class'])\n",
    "\n",
    "data = pd.DataFrame(points, columns=['X','Y'])\n",
    "# data.to_csv('data_XY.csv', index=False)\n",
    "\n",
    "# Concatenating both classes and Keypoints and saving the dataset\n",
    "dataset = pd.concat([data,classes],axis=1)\n",
    "dataset.to_csv('KPts_dataset.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
